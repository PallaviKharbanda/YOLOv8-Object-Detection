{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Modes:\n",
        "\n",
        "train, val, predict\n",
        "\n",
        "#Tasks:\n",
        "\n",
        "detect, segment, classify\n",
        "\n",
        "#Data:\n",
        "\n",
        "Format can be differ for task type, Supports data.yaml, data_folder, data_name"
      ],
      "metadata": {
        "id": "P7JZ3IeCX36S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "J-UNok5za4EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrH9uyhXa6lC",
        "outputId": "bc20a414-966a-4842-c3fb-2313c7477fe2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.9/dist-packages (8.0.87)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.0.0+cu118)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.15.1+cu118)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.21.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (5.12.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->ultralytics) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CMD"
      ],
      "metadata": {
        "id": "uVvHxTpnayvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDlljHgu9wCd",
        "outputId": "83d80260-bb4c-47c1-f85c-4b6a80e14cf2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x1ROswscR6o",
        "outputId": "a67a4238-6567-4450-eb22-7b2a08e4d869"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/MyDrive/Computer Vision/Yolov8-object detection\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icGMdbpP9x7p",
        "outputId": "03f8f53a-1f68-42c1-860a-14a1d199d86f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Computer Vision/Yolov8-object detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6wyc_c--Kn9",
        "outputId": "4ccbe4d7-7a85-413e-cd84-1ae29c67c283"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Computer Vision/Yolov8-object detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZlSaQUB-LnR",
        "outputId": "00e41b05-39a6-4758-8af8-6bdc76bdd6a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Detection:"
      ],
      "metadata": {
        "id": "oDJiCWsuYksB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M7dGopyXtph",
        "outputId": "95ed8456-047f-4197-d753-9e0e14b26652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100% 6.23M/6.23M [00:00<00:00, 8.98MB/s]\n",
            "Ultralytics YOLOv8.0.87 ðŸš€ Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Computer Vision/Yolov8-object detection/data/train/images/54.jpeg: 448x640 1 person, 1 clock, 61.6ms\n",
            "Speed: 0.7ms preprocess, 61.6ms inference, 97.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=predict model=yolov8n.pt source=\"/content/drive/MyDrive/Computer Vision/Yolov8-object detection/data/train/images/54.jpeg\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Segmentation:"
      ],
      "metadata": {
        "id": "LhfAQY28Y5Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=segment mode=predict model=yolov8n-seg.pt source=\"/content/drive/MyDrive/Computer Vision/Yolov8-object detection/data/train/images/54.jpeg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9U1fjFLY9qZ",
        "outputId": "634acabd-4532-4dc6-af21-ad9578282929"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt to yolov8n-seg.pt...\n",
            "100% 6.73M/6.73M [00:00<00:00, 177MB/s]\n",
            "Ultralytics YOLOv8.0.87 ðŸš€ Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-seg summary (fused): 195 layers, 3404320 parameters, 0 gradients, 12.6 GFLOPs\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Computer Vision/Yolov8-object detection/data/train/images/54.jpeg: 448x640 1 person, 84.1ms\n",
            "Speed: 0.7ms preprocess, 84.1ms inference, 83.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8Phe_OFcZGA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Script"
      ],
      "metadata": {
        "id": "dvKMoCCkasmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a segmentation model\n",
        "model = YOLO(\"yolov8n-seg.pt\")  \n",
        "model.predict(source=\"/content/drive/MyDrive/Computer Vision/Yolov8-object detection/data/train/images/54.jpeg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "471GwJWFaO85",
        "outputId": "68e85b99-0975-43d4-86d8-fdecd98342ec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Computer Vision/Yolov8-object detection/data/train/images/54.jpeg: 448x640 1 person, 79.1ms\n",
            "Speed: 0.7ms preprocess, 79.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes', 'masks']\n",
              " masks: ultralytics.yolo.engine.results.Masks object\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " orig_img: array([[[148, 133, 117],\n",
              "         [157, 142, 126],\n",
              "         [167, 152, 136],\n",
              "         ...,\n",
              "         [177, 151, 114],\n",
              "         [231, 212, 179],\n",
              "         [255, 246, 217]],\n",
              " \n",
              "        [[147, 132, 116],\n",
              "         [155, 140, 124],\n",
              "         [164, 149, 133],\n",
              "         ...,\n",
              "         [182, 156, 119],\n",
              "         [233, 214, 181],\n",
              "         [255, 246, 217]],\n",
              " \n",
              "        [[146, 131, 115],\n",
              "         [152, 137, 121],\n",
              "         [159, 144, 128],\n",
              "         ...,\n",
              "         [189, 166, 128],\n",
              "         [234, 216, 185],\n",
              "         [255, 246, 218]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[126, 112,  94],\n",
              "         [126, 112,  94],\n",
              "         [126, 111,  95],\n",
              "         ...,\n",
              "         [162, 132, 113],\n",
              "         [162, 132, 113],\n",
              "         [162, 132, 113]],\n",
              " \n",
              "        [[125, 111,  93],\n",
              "         [125, 111,  93],\n",
              "         [125, 110,  94],\n",
              "         ...,\n",
              "         [158, 131, 111],\n",
              "         [160, 130, 111],\n",
              "         [160, 130, 111]],\n",
              " \n",
              "        [[124, 110,  92],\n",
              "         [124, 110,  92],\n",
              "         [125, 110,  94],\n",
              "         ...,\n",
              "         [156, 129, 109],\n",
              "         [158, 128, 109],\n",
              "         [158, 128, 109]]], dtype=uint8)\n",
              " orig_shape: (183, 275)\n",
              " path: '/content/drive/MyDrive/Computer Vision/Yolov8-object detection/data/train/images/54.jpeg'\n",
              " probs: None\n",
              " speed: {'preprocess': 0.7221698760986328, 'inference': 79.1327953338623, 'postprocess': 2.9087066650390625}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Classification:"
      ],
      "metadata": {
        "id": "a8ocmWB6cww5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=classify mode=predict model=yolov8n-cls.pt source=\"/content/drive/MyDrive/Computer Vision/Yolov8-object detection/data/train/images/54.jpeg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLNSTczyccx6",
        "outputId": "f62905c4-972e-4b3e-e10d-3855c253c30c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt to yolov8n-cls.pt...\n",
            "100% 5.28M/5.28M [00:00<00:00, 17.9MB/s]\n",
            "Ultralytics YOLOv8.0.87 ðŸš€ Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 2715880 parameters, 0 gradients, 4.3 GFLOPs\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Computer Vision/Yolov8-object detection/data/train/images/54.jpeg: 224x224 academic_gown 0.94, mortarboard 0.01, jinrikisha 0.01, paddle 0.01, vestment 0.00, 4.5ms\n",
            "Speed: 0.5ms preprocess, 4.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/classify/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2q6tQPgccvo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}